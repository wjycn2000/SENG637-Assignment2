

[1 Introduction](#heading=)

[2 Detailed Description of Unit Test Strategy](#heading=)

[2.1 Testing Scope](#heading=)

[2.2 Test Design Approach](#heading=)

[2.3 Test Strategy Implementation](#heading=)

[2.4 Execution and Evaluation](#heading=)

[3 Test Cases Developed](#heading=)

[3.1 Mohammad Abu Saleh Test Cases Developed](#heading=)

[3.1.1 Test Case Design Approach](#heading=)

[3.1.2 Test Case Documentation](#heading=)

[3.1.3 DataUtilities Class Test Cases](#heading=)

[3.1.3.1 calculateColumnTotal Method Testing](#heading=)

[Test Case ID: TC\_DU\_001](#heading=)

[Test Case ID: TC\_DU\_002](#heading=)

[Test Case ID: TC\_DU\_003](#heading=)

[Test Case ID: TC\_DU\_004](#heading=)

[3.1.3.2 calculateRowTotal Method Testing](#heading=)

[Test Case ID: TC\_DU\_005](#heading=)

[Test Case ID: TC\_DU\_006](#heading=)

[Test Case ID: TC\_DU\_007](#heading=)

[Test Case ID: TC\_DU\_008](#heading=)

[3.1.4 Range Class Test Cases](#heading=)

[3.1.4.1 equals Method Testing](#heading=)

[Test Case ID: TC\_RNG\_001](#heading=)

[Test Case ID: TC\_RNG\_002](#heading=)

[Test Case ID: TC\_RNG\_003](#heading=)

[Test Case ID: TC\_RNG\_004](#heading=)

[3.1.4.2 expand Method Testing](#heading=)

[Test Case ID: TC\_RNG\_005](#heading=)

[Test Case ID: TC\_RNG\_006](#heading=)

[Test Case ID: TC\_RNG\_007](#heading=)

[Test Case ID: TC\_RNG\_008](#heading=)

[3.1.4.3 expandToInclude Method Testing](#heading=)

[Test Case ID: TC\_RNG\_009](#heading=)

[Test Case ID: TC\_RNG\_010](#heading=)

[Test Case ID: TC\_RNG\_011](#heading=)

[Test Case ID: TC\_RNG\_012](#heading=)

[3.1.4.4 getLowerBound Method Testing](#heading=)

[Test Case ID: TC\_RNG\_013](#heading=)

[Test Case ID: TC\_RNG\_014](#heading=)

[Test Case ID: TC\_RNG\_015](#heading=)

[Test Case ID: TC\_RNG\_016](#heading=)

[3.1.4.5 getUpperBound Method Testing](#heading=)

[Test Case ID: TC\_RNG\_017](#heading=)

[Test Case ID: TC\_RNG\_018](#heading=)

[Test Case ID: TC\_RNG\_019](#heading=)

[Test Case ID: TC\_RNG\_020](#heading=)

[3.1.4.6 hashCode Method Testing](#heading=)

[Test Case ID: TC\_RNG\_021](#heading=)

[Test Case ID: TC\_RNG\_022](#heading=)

[Test Case ID: TC\_RNG\_023](#heading=)

[Test Case ID: TC\_RNG\_024](#heading=)

[3.1.4.7 intersects Method Testing](#heading=)

[Test Case ID: TC\_RNG\_025](#heading=)

[Test Case ID: TC\_RNG\_026](#heading=)

[Test Case ID: TC\_RNG\_027](#heading=)

[Test Case ID: TC\_RNG\_028](#heading=)

[3.1.4.8 shift Method Testing](#heading=)

[Test Case ID: TC\_RNG\_029](#heading=)

[Test Case ID: TC\_RNG\_030](#heading=)

[Test Case ID: TC\_RNG\_031](#heading=)

[Test Case ID: TC\_RNG\_032](#heading=)

[3.2 Abubakar Khalid Test Cases Developed](#heading=)

[3.2.1 Test Strategy](#3.2.1-test-strategy)

[Test Types](#test-types)

[3.2.2 Test Case Documentation for createNumberArray()](#3.2.2-test-case-documentation-for-createnumberarray\(\))

[3.2.3 Notes on Results](#3.2.3-notes-on-results)

[3.2.4 Test Case Documentation for createNumberArray2D()](#3.2.4-test-case-documentation-for-createnumberarray2d\(\))

[3.2.5 Notes on Results](#3.2.5-notes-on-results)

[3.3 Ahmed Shehata Test Cases Developed](#heading=)

[3.3.1 Test Strategy](#3.3.1-test-strategy)

[3.3.2 Test Case Documentation for Each Method](#3.3.2-test-case-documentation-for-each-method)

[Method: contains(double value)](#3.3.2.1-method:-contains\(double-value\))

[Method: getCentralValue()](#3.3.2.2-method:-getcentralvalue\(\))

[Method: getLength()](#3.3.2.3-method:-getlength\(\))

[3.4 Jinyu Wang Test Cases Developed](#heading=)

[3.4.1 Test Ranger.combine()](#3.4.1-test-ranger.combine\(\))

[3.4.1.1 Test strategies](#3.4.1.1-test-strategies)

[1\. Equivalence Class Partitioning (ECP)](#1.-equivalence-class-partitioning-\(ecp\))

[2\. Boundary Value Analysis (BVA)](#2.-boundary-value-analysis-\(bva\))

[3.4.1.2 Test cases design](#3.4.1.2-test-cases-design)

[A. Handling Null Inputs](#a.-handling-null-inputs)

[B. Merging Different Range Scenarios](#b.-merging-different-range-scenarios)

[C. Boundary Conditions](#c.-boundary-conditions)

[D. Handling Single-Point Ranges](#d.-handling-single-point-ranges)

[3.4.2 Test Range.constrain()](#3.4.2-test-range.constrain\(\))

[3.4.2.1 Test strategy](#3.4.2.1-test-strategy)

[Equivalence Class Partitioning (ECP)](#equivalence-class-partitioning-\(ecp\))

[Boundary Value Analysis (BVA)](#boundary-value-analysis-\(bva\))

[3.4.2.2 Test case design](#3.4.2.2-test-case-design)

[A. Inside the Range](#a.-inside-the-range)

[B. Boundary Cases](#b.-boundary-cases)

[C. Below the Range](#c.-below-the-range)

[D. Above the Range](#d.-above-the-range)

[3.4.3 Test DataUtilities.getCumulativePercentages()](#3.4.3-test-datautilities.getcumulativepercentages\(\))

[3.4.3.1 Test strategy](#3.4.3.1-test-strategy)

[Equivalence Class Partitioning (ECP)](#equivalence-class-partitioning-\(ecp\)-1)

[Boundary Value Analysis (BVA)](#boundary-value-analysis-\(bva\)-1)

[3.4.3.2 Test case design](#3.4.3.2-test-case-design)

[A. Valid Cases](#a.-valid-cases)

[B. Edge Cases](#b.-edge-cases)

[C. Invalid Cases](#c.-invalid-cases)

[4 How the Team Work/Effort was Divided and Managed](#heading=)

[4.1 Responsibilities:](#heading=)

[4.2 Collaboration and Coordination:](#heading=)

[5 Difficulties Encountered, Challenges Overcome, and Lessons Learned](#heading=)

[6 Comments/Feedback on the Lab Itself](#heading=)

# 

# 1 Introduction

In this assignment, we focus on applying requirement-based testing techniques to JFreeChart, an open-source charting framework for Java applications. The objective is to develop a robust unit testing strategy that ensures the correctness and reliability of key components within the framework. By leveraging JUnit for automated testing and incorporating mock objects where necessary, we aim to validate the functionality of selected methods in the org.jfree.data.Range and org.jfree.data.DataUtilities classes.

This assignment follows a structured approach, beginning with setting up the development environment in Eclipse and integrating necessary libraries, including JUnit and a mocking framework such as jMock. We will design and implement test cases using black-box testing techniques, including equivalence class testing, boundary value analysis, robustness testing, and worst-case testing. These test cases will be executed to evaluate the behavior of the software under various conditions.

Our work is divided into key phases: understanding the system under test (JFreeChart), designing test cases based on Javadoc specifications, implementing the tests, executing them, and analyzing the results. The findings will be documented in this report, along with reflections on the challenges encountered and lessons learned during the testing process.

# 2 Detailed Description of Unit Test Strategy

## 2.1 Testing Scope

The scope of our testing is limited to two primary classes from the org.jfree.data package:

* **org.jfree.data.Range** (5 selected methods out of 15 as required, and 8 more to get a Full Mark on the assignment)  
* **org.jfree.data.DataUtilities** (all 5 methods)

These classes have been selected based on their critical role in the JFreeChart framework, and the testing strategy will ensure comprehensive validation of their functionalities using structured test design approaches.

## 2.2 Test Design Approach

We employ black-box testing techniques, including:

* **Equivalence Partitioning**: Identifying valid and invalid input ranges for each method.  
* **Boundary Value Analysis**: Testing the boundaries of input domains to detect edge-case failures.  
* **Robustness Testing**: Evaluating how the system handles unexpected or erroneous inputs.  
* **Worst-case Testing**: Combining extreme values to test method resilience.

## 2.3 Test Strategy Implementation

1. **Unit Test Framework**: The test suite will be implemented using JUnit 4/5.  
2. **Mocking Framework**: We will use jMock for methods requiring mocked objects (e.g., Values2D, KeyedValues).  
3. **Test Case Structure**:   
   * Each test method will correspond to a single equivalence class or boundary value.  
   * Assertions will be used to validate expected outcomes based on method specifications.

## 2.4 Execution and Evaluation

* The test suite will be executed on modified versions of JFreeChart to assess method correctness.  
* Test failures will be analyzed to determine discrepancies between expected and actual results.  
* The report will document key findings, including defect analysis and coverage evaluation.

# 3 Test Cases Developed

## 3.1 Mohammad Abu Saleh Test Cases Developed

### 3.1.1 Test Case Design Approach

The test cases are designed following a structured approach based on the principles of black-box testing. The key steps involved in test case design are:

1. **Deriving the Domain for Each Input Variable**:   
   * Each method's parameters are analyzed to determine their valid and invalid input domains.  
2. **Defining Equivalence Classes**:   
   * Inputs are categorized into valid and invalid equivalence classes.  
3. **Applying Boundary Value Analysis**:   
   * The lower and upper limits of each input range are tested.  
4. **Conducting Robustness and Worst-case Testing**:   
   * Invalid and extreme values are considered to check system stability.

### 3.1.2 Test Case Documentation

Each test case is documented using the following structure:

* **Test Case ID**  
* **Test Objective**  
* **Test Input**  
* **Expected Output**  
* **Test Steps**  
* **Actual Result (upon execution)**  
* **Pass/Fail Criteria**

### 3.1.3 DataUtilities Class Test Cases

#### *3.1.3.1 calculateColumnTotal Method Testing*

##### Test Case ID: TC\_DU\_001

**Test Objective:** Equivalence Class Testing \- Verify that calculateColumnTotal correctly calculates the sum of column values in a Values2D dataset.

**Test Input:**

* Values2D dataset with multiple numeric values

* Column index \= 1

**Expected Output:**

* The method returns the correct sum of all numeric values in column 1\.

**Test Steps:**

1. Create a Values2D dataset with predefined numeric values.

2. Call calculateColumnTotal(data, 1).

3. Compare the returned result with the expected sum.

**Actual Result (upon execution):**

* Test Pass: testCalculateColumnTotal\_ValidData

**Pass/Fail Criteria:**

* The test passes if the returned sum matches the expected sum.

##### Test Case ID: TC\_DU\_002

**Test Objective:** Boundary Value Analysis \- Verify calculateColumnTotal behavior with an empty dataset.

**Test Input:**

* Values2D dataset with no values.

* Column index \= 0

**Expected Output:**

* The method returns 0\.

**Test Steps:**

1. Create an empty Values2D dataset.

2. Call calculateColumnTotal(data, 0).

3. Verify that the result is 0\.

**Actual Result (upon execution):**

* Test Pass: testCalculateColumnTotal\_EmptyDataset

**Pass/Fail Criteria:**

* The test passes if the returned value is 0\.

##### Test Case ID: TC\_DU\_003

**Test Objective:** Robustness Testing \- Verify handling of null values within a dataset.

**Test Input:**

* Values2D dataset containing null values.

* Column index \= 2

**Expected Output:**

* The method skips null values and returns the sum of non-null values.

**Test Steps:**

1. Create a Values2D dataset containing null values.

2. Call calculateColumnTotal(data, 2).

3. Verify that the returned sum excludes null values.

**Actual Result (upon execution):**

* Test Failure: testCalculateColumnTotal\_WithNullValues

**Pass/Fail Criteria:**

* The test passes if the returned sum excludes null values.

##### Test Case ID: TC\_DU\_004

**Test Objective:** Worst-Case Testing \- Evaluate performance with large datasets.

**Test Input:**

* Values2D dataset with 100,000 numeric values.

* Column index \= 3

**Expected Output:**

* The method correctly sums all values without performance degradation.

**Test Steps:**

1. Create a large Values2D dataset.

2. Call calculateColumnTotal(data, 3).

3. Compare the result with expected large dataset sum.

**Actual Result (upon execution):**

* Test Failure: testCalculateColumnTotal\_LargeDataset

**Pass/Fail Criteria:**

* The test passes if the sum is accurate and execution time is within acceptable limits.

#### *3.1.3.2 calculateRowTotal Method Testing*

##### Test Case ID: TC\_DU\_005

**Test Objective:** Equivalence Class Testing \- Validate row sum calculations.

**Test Input:**

* Values2D dataset with multiple numeric values

* Row index \= 1

**Expected Output:**

* The method returns the correct sum of all numeric values in row 1\.

**Test Steps:**

1. Create a Values2D dataset with predefined numeric values.

2. Call calculateRowTotal(data, 1).

3. Compare the returned result with the expected sum.

**Actual Result (upon execution):**

* Test Failure: testCalculateRowTotal\_ValidData

**Pass/Fail Criteria:**

* The test passes if the returned sum matches the expected sum.

##### Test Case ID: TC\_DU\_006

**Test Objective:** Boundary Value Analysis \- Check row limits and empty row scenarios.

**Test Input:**

* Values2D dataset with no values.

* Row index \= 0

**Expected Output:**

* The method returns 0\.

**Test Steps:**

1. Create an empty Values2D dataset.

2. Call calculateRowTotal(data, 0).

3. Verify that the result is 0\.

**Actual Result (upon execution):**

* Test Pass: testCalculateRowTotal\_EmptyDataset

**Pass/Fail Criteria:**

* The test passes if the returned value is 0\.

##### Test Case ID: TC\_DU\_007

**Test Objective:** Robustness Testing \- Test behavior for missing data points.

**Test Input:**

* Values2D dataset containing null values.

* Row index \= 2

**Expected Output:**

* The method skips null values and returns the sum of non-null values.

**Test Steps:**

1. Create a Values2D dataset containing null values.

2. Call calculateRowTotal(data, 2).

3. Verify that the returned sum excludes null values.

**Actual Result (upon execution):**

* Test Pass: testCalculateRowTotal\_WithNullValues

**Pass/Fail Criteria:**

* The test passes if the returned sum excludes null values.

##### Test Case ID: TC\_DU\_008

**Test Objective:** Worst-Case Testing \- Use large row values to test stability.

**Test Input:**

* Values2D dataset with 100,000 numeric values.

* Row index \= 3

**Expected Output:**

* The method correctly sums all values without performance degradation.

**Test Steps:**

1. Create a large Values2D dataset.

2. Call calculateRowTotal(data, 3).

3. Compare the result with expected large dataset sum.

**Actual Result (upon execution):**

* Test Failure: testCalculateRowTotal\_WithNullValues

**Pass/Fail Criteria:**

* The test passes if the sum is accurate and execution time is within acceptable limits.

### 3.1.4 Range Class Test Cases

#### *3.1.4.1 equals Method Testing*

##### Test Case ID: TC\_RNG\_001

**Test Objective:** Equivalence Class Testing \- Compare with different object types.

**Test Input:**

* Range object compared with an unrelated object (e.g., String, Integer).

**Expected Output:**

* The method returns false.

**Test Steps:**

1. Create a Range object.

2. Compare it with an unrelated object type.

3. Verify that the method returns false.

**Actual Result (upon execution):**

* Test Pass: testEquals\_WithDifferentObjectTypes

**Pass/Fail Criteria:**

* The test passes if the method correctly returns false for unrelated object types.

##### Test Case ID: TC\_RNG\_002

**Test Objective:** Boundary Value Analysis \- Compare with objects having similar but slightly varied values.

**Test Input:**

* Range(5,10) compared with Range(5.0001, 10.0001).

**Expected Output:**

* The method returns false.

**Test Steps:**

1. Create two Range objects with close but distinct values.

2. Compare them using equals.

3. Verify that the method returns false.

**Actual Result (upon execution):**

* Test Pass: testEquals\_WithSlightlyDifferentValues

**Pass/Fail Criteria:**

* The test passes if the method correctly identifies slight variations.

##### Test Case ID: TC\_RNG\_003

**Test Objective:** Robustness Testing \- Check null object comparison.

**Test Input:**

* Range object compared with null.

**Expected Output:**

* The method returns false.

**Test Steps:**

1. Create a Range object.

2. Compare it with null.

3. Verify that the method returns false.

**Actual Result (upon execution):**

* Test Pass: testEquals\_WithNullObject

**Pass/Fail Criteria:**

* The test passes if false is returned for a null comparison.

##### Test Case ID: TC\_RNG\_004

**Test Objective:** Worst-Case Testing \- Compare with large object structures.

**Test Input:**

* Range(-1e9, 1e9) compared with an identical large range.

**Expected Output:**

* The method returns true.

**Test Steps:**

1. Create two Range objects with very large values.

2. Compare them using equals.

3. Verify that the method returns true.

**Actual Result (upon execution):**

* Test Pass: testEquals\_WithLargeRangeValues

**Pass/Fail Criteria:**

* The test passes if the method correctly identifies equality in large values.

#### *3.1.4.2 expand Method Testing*

##### Test Case ID: TC\_RNG\_005

**Test Objective: Equivalence Class Testing \- Validate range expansion with positive, negative, and zero margins.**

**Test Input:**

* **Range(5,10) expanded with lowerMargin \= 0.2, upperMargin \= 0.3.**

* **Range(5,10) expanded with lowerMargin \= \-0.2, upperMargin \= \-0.3.**

* **Range(5,10) expanded with lowerMargin \= 0, upperMargin \= 0\.**

**Expected Output:**

* **The method correctly expands or contracts the range according to the margin values.**

**Test Steps:**

1. **Create a Range(5,10).**

2. **Expand it with various positive, negative, and zero margins.**

3. **Verify that the returned range values match expected results.**

**Actual Result (upon execution):**

* **Test Failure: testExpand\_WithZeroMargins**

* **Test Failure: testExpand\_WithPositiveMargins**

* **Test Pass: testExpand\_WithNegativeMargins**

**Pass/Fail Criteria:**

* **The test passes if the method returns the expected expanded or contracted range.**

##### Test Case ID: TC\_RNG\_006

**Test Objective: Boundary Value Analysis \- Test edge values of margin expansion.**

**Test Input:**

* **Range(5,10) expanded with extreme margin values, such as 1.0 and \-1.0.**

**Expected Output:**

* **The method correctly handles maximum and minimum margin values without exceeding expected bounds.**

**Test Steps:**

1. **Create a Range(5,10).**

2. **Expand it with edge margin values.**

3. **Verify that the returned range respects expected behavior.**

**Actual Result (upon execution):**

* **Test Pass: testExpand\_WithMinimumMargins**

* **Test Failure: testExpand\_WithMaximumMargins**

**Pass/Fail Criteria:**

* **The test passes if the returned range is within expected limits.**

##### Test Case ID: TC\_RNG\_007

**Test Objective: Robustness Testing \- Test invalid input handling (e.g., null range, extreme margins).**

**Test Input:**

* **null range expanded with valid margin values.**

* **Range(5,10) expanded with extreme negative and positive margins.**

**Expected Output:**

* **The method throws an appropriate exception for invalid inputs.**

**Test Steps:**

1. **Attempt to expand a null range.**

2. **Expand Range(5,10) with extreme margin values.**

3. **Verify that the method correctly handles invalid cases.**

**Actual Result (upon execution):**

* **Test Failure: testExpand\_WithExtremeMargins**

* **Test Pass: testExpand\_WithExtremeNegativeMargins**

* **Test Pass: testExpand\_WithNullRange**

**Pass/Fail Criteria:**

* **The test passes if appropriate exceptions are thrown or invalid expansions are handled gracefully.**

##### Test Case ID: TC\_RNG\_008

**Test Objective: Worst-Case Testing \- Expand range with maximum possible values.**

**Test Input:**

* **Range(-1e9,1e9) expanded with lowerMargin \= 0.5 and upperMargin \= 0.5.**

**Expected Output:**

* **The method correctly expands the large range without integer overflow or performance degradation.**

**Test Steps:**

1. **Create a Range(-1e9,1e9).**

2. **Expand it with large margin values.**

3. **Verify that the method executes efficiently and produces correct results.**

**Actual Result (upon execution):**

* **Test Failure**

**Pass/Fail Criteria:**

* **The test passes if the method correctly expands large range values and executes within acceptable time limits.**

#### *3.1.4.3 expandToInclude Method Testing*

##### Test Case ID: TC\_RNG\_009

**Test Objective:** Equivalence Class Testing \- Check expansion behavior with in-range and out-of-range values.

**Test Input:**

* Range(5,10) expanded to include value 7 (in-range value).

* Range(5,10) expanded to include value 12 (out-of-range value).

**Expected Output:**

* The method returns a new range that includes the specified value.

**Test Steps:**

1. Create a Range(5,10).

2. Expand it to include 7\.

3. Expand it to include 12\.

4. Verify the expected expanded range.

**Actual Result (upon execution):**

* Test Failure: testExpandToInclude\_WithInRangeValue

* Test Failure: testExpandToInclude\_WithOutOfRangeValue

**Pass/Fail Criteria:**

* The test passes if the method correctly expands the range.

##### Test Case ID: TC\_RNG\_010

**Test Objective:** Boundary Value Analysis \- Verify inclusion at exact range limits.

**Test Input:**

* Range(5,10) expanded to include 5 (lower bound).

* Range(5,10) expanded to include 10 (upper bound).

**Expected Output:**

* The method returns the original range without modification.

**Test Steps:**

1. Create a Range(5,10).

2. Expand it to include 5\.

3. Expand it to include 10\.

4. Verify the returned range remains unchanged.

**Actual Result (upon execution):**

* Test Failure: testExpandToInclude\_AtLowerBound

* Test Failure: testExpandToInclude\_AtUpperBound

**Pass/Fail Criteria:**

* The test passes if the method does not alter the range for boundary values.

##### Test Case ID: TC\_RNG\_011

**Test Objective:** Robustness Testing \- Handle invalid input scenarios.

**Test Input:**

* null range expanded to include a valid number.

* Range(5,10) expanded with an extremely large or small number.

**Expected Output:**

* The method throws an appropriate exception or handles the invalid input gracefully.

**Test Steps:**

1. Attempt to expand a null range with a valid number.

2. Expand Range(5,10) with an extreme value.

3. Verify that exceptions are thrown or handled correctly.

**Actual Result (upon execution):**

* Test Pass: testExpandToInclude\_WithNullRange

* Test Failure: testExpandToInclude\_WithExtremeLargeValue

* Test Failure: testExpandToInclude\_WithExtremeSmallValue

**Pass/Fail Criteria:**

* The test passes if exceptions are properly handled.

##### Test Case ID: TC\_RNG\_012

**Test Objective:** Worst-Case Testing \- Expand range to its extreme bounds.

**Test Input:**

* Range(-1e9,1e9) expanded to include 1e12.

**Expected Output:**

* The method correctly expands the range without performance degradation.

**Test Steps:**

1. Create a Range(-1e9,1e9).

2. Expand it to include 1e12.

3. Verify the execution efficiency and correctness.

**Actual Result (upon execution):**

* Test Failure: testExpandToInclude\_WithExtremeUpperBound

**Pass/Fail Criteria:**

* The test passes if the method correctly expands the range while maintaining performance.

#### *3.1.4.4 getLowerBound Method Testing*

##### Test Case ID: TC\_RNG\_013

**Test Objective:** Equivalence Class Testing \- Validate correct retrieval of bounds.

**Test Input:**

* Range(5,10), retrieving lower bound.

* Range(-5,5), retrieving lower bound.

**Expected Output:**

* The method returns the correct lower bound value.

**Test Steps:**

1. Create a Range(5,10).

2. Retrieve the lower bound.

3. Create a Range(-5,5).

4. Retrieve the lower bound.

5. Verify the returned values.

**Actual Result (upon execution):**

* Test Pass: testGetLowerBound\_WithPositiveRange

* Test Pass: testGetLowerBound\_WithNegativeRange

**Pass/Fail Criteria:**

* The test passes if the method correctly retrieves the lower bound.

##### Test Case ID: TC\_RNG\_014

**Test Objective:** Boundary Value Analysis \- Test minimum and maximum range values.

**Test Input:**

* Range(Double.MIN\_VALUE, 5), retrieving lower bound.

* Range(-5, Double.MAX\_VALUE), retrieving lower bound.

**Expected Output:**

* The method correctly retrieves the minimum and maximum possible lower bound values.

**Test Steps:**

1. Create a Range(Double.MIN\_VALUE, 5).

2. Retrieve the lower bound.

3. Create a Range(-5, Double.MAX\_VALUE).

4. Retrieve the lower bound.

5. Verify the returned values.

**Actual Result (upon execution):**

* Test Pass: testGetLowerBound\_WithMinValue

* Test Pass: testGetLowerBound\_WithMaxValue

**Pass/Fail Criteria:**

* The test passes if the method correctly handles extreme lower bound values.

##### Test Case ID: TC\_RNG\_015

**Test Objective:** Robustness Testing \- Ensure proper handling of negative ranges.

**Test Input:**

* Range(-10,-1), retrieving lower bound.

**Expected Output:**

* The method correctly returns the negative lower bound value.

**Test Steps:**

1. Create a Range(-10,-1).

2. Retrieve the lower bound.

3. Verify the returned value.

**Actual Result (upon execution):**

* Test Pass: testGetLowerBound\_WithNegativeRange

**Pass/Fail Criteria:**

* The test passes if the method correctly retrieves negative lower bounds.

##### Test Case ID: TC\_RNG\_016

**Test Objective:** Worst-Case Testing \- Retrieve bounds from a highly complex range structure.

**Test Input:**

* Range(-1e9,1e9), retrieving lower bound.

**Expected Output:**

* The method correctly retrieves the lower bound without performance degradation.

**Test Steps:**

1. Create a Range(-1e9,1e9).

2. Retrieve the lower bound.

3. Verify the execution efficiency and correctness.

**Actual Result (upon execution):**

* Test Pass: testGetLowerBound\_WithLargeRange

**Pass/Fail Criteria:**

* The test passes if the method correctly retrieves the lower bound while maintaining performance.

#### *3.1.4.5 getUpperBound Method Testing*

##### Test Case ID: TC\_RNG\_017

**Test Objective:** Equivalence Class Testing \- Validate correct retrieval of bounds.

**Test Input:**

* Range(5,10), retrieving upper bound.

* Range(-5,5), retrieving upper bound.

**Expected Output:**

* The method returns the correct upper bound value.

**Test Steps:**

1. Create a Range(5,10).

2. Retrieve the upper bound.

3. Create a Range(-5,5).

4. Retrieve the upper bound.

5. Verify the returned values.

**Actual Result (upon execution):**

* Test Failure: testGetUpperBound\_WithPositiveRange

* Test Failure: testGetUpperBound\_WithNegativeRange

**Pass/Fail Criteria:**

* The test passes if the method correctly retrieves the upper bound.

##### Test Case ID: TC\_RNG\_018

**Test Objective:** Boundary Value Analysis \- Test minimum and maximum range values.

**Test Input:**

* Range(5, Double.MAX\_VALUE), retrieving upper bound.

* Range(Double.MIN\_VALUE, 10), retrieving upper bound.

**Expected Output:**

* The method correctly retrieves the minimum and maximum possible upper bound values.

**Test Steps:**

1. Create a Range(5, Double.MAX\_VALUE).

2. Retrieve the upper bound.

3. Create a Range(Double.MIN\_VALUE, 10).

4. Retrieve the upper bound.

5. Verify the returned values.

**Actual Result (upon execution):**

* Test Failure: testGetUpperBound\_WithMinValue

* Test Failure: testGetUpperBound\_WithMaxValue

**Pass/Fail Criteria:**

* The test passes if the method correctly handles extreme upper bound values.

##### Test Case ID: TC\_RNG\_019

**Test Objective:** Robustness Testing \- Ensure proper handling of negative ranges.

**Test Input:**

* Range(-10,-1), retrieving upper bound.

**Expected Output:**

* The method correctly returns the negative upper bound value.

**Test Steps:**

1. Create a Range(-10,-1).

2. Retrieve the upper bound.

3. Verify the returned value.

**Actual Result (upon execution):**

* Test Failure: testGetUpperBound\_WithNegativeRange

**Pass/Fail Criteria:**

* The test passes if the method correctly retrieves negative upper bounds.

##### Test Case ID: TC\_RNG\_020

**Test Objective:** Worst-Case Testing \- Retrieve bounds from a highly complex range structure.

**Test Input:**

* Range(-1e9,1e9), retrieving upper bound.

**Expected Output:**

* The method correctly retrieves the upper bound without performance degradation.

**Test Steps:**

1. Create a Range(-1e9,1e9).

2. Retrieve the upper bound.

3. Verify the execution efficiency and correctness.

**Actual Result (upon execution):**

* Test Failure: testGetUpperBound\_WithLargeRange

**Pass/Fail Criteria:**

* The test passes if the method correctly retrieves the upper bound while maintaining performance.

#### *3.1.4.6 hashCode Method Testing*

##### Test Case ID: TC\_RNG\_021

**Test Objective:** Equivalence Class Testing \- Validate unique hash codes for different ranges.

**Test Input:**

* Range(5,10), generating hash code.

* Range(-5,5), generating hash code.

* Range(0,0), generating hash code.

**Expected Output:**

* Each unique range produces a distinct hash code.

**Test Steps:**

1. Create a Range(5,10) and generate its hash code.

2. Create a Range(-5,5) and generate its hash code.

3. Create a Range(0,0) and generate its hash code.

4. Verify that each range produces a unique hash code.

**Actual Result (upon execution):**

* Test Pass: testHashCode\_ForDifferentRanges

**Pass/Fail Criteria:**

* The test passes if each unique range produces a distinct hash code.

##### Test Case ID: TC\_RNG\_022

**Test Objective:** Boundary Value Analysis \- Test collision cases for similar values.

**Test Input:**

* Range(5,10), generating hash code.

* Range(5.0001,10.0001), generating hash code.

**Expected Output:**

* Similar but slightly varied ranges should ideally produce different hash codes.

**Test Steps:**

1. Create a Range(5,10) and generate its hash code.

2. Create a Range(5.0001,10.0001) and generate its hash code.

3. Verify that the generated hash codes are distinct.

**Actual Result (upon execution):**

* Test Pass: testHashCode\_ForSimilarRanges

**Pass/Fail Criteria:**

* The test passes if the method minimizes hash collisions for near-identical ranges.

##### Test Case ID: TC\_RNG\_023

**Test Objective:** Robustness Testing \- Verify handling of extreme values.

**Test Input:**

* Range(Double.MIN\_VALUE, Double.MAX\_VALUE), generating hash code.

* Range(-Double.MAX\_VALUE, Double.MAX\_VALUE), generating hash code.

**Expected Output:**

* The method correctly generates hash codes for extreme ranges without error.

**Test Steps:**

1. Create a Range(Double.MIN\_VALUE, Double.MAX\_VALUE) and generate its hash code.

2. Create a Range(-Double.MAX\_VALUE, Double.MAX\_VALUE) and generate its hash code.

3. Verify that the method does not fail or return incorrect values.

**Actual Result (upon execution):**

* Test Pass: testHashCode\_WithExtremeValues

**Pass/Fail Criteria:**

* The test passes if the method correctly handles extreme values without error.

##### Test Case ID: TC\_RNG\_024

**Test Objective:** Worst-Case Testing \- Generate hash codes for a large dataset.

**Test Input:**

* 100,000 different Range objects, each with unique values.

**Expected Output:**

* The method efficiently generates hash codes without excessive collisions or performance issues.

**Test Steps:**

1. Generate 100,000 unique Range objects.

2. Compute the hash code for each.

3. Verify the execution efficiency and correctness.

**Actual Result (upon execution):**

* Test Failure: testHashCode\_WithLargeDataset

**Pass/Fail Criteria:**

* The test passes if hash codes are efficiently generated and unique across large datasets.

#### *3.1.4.7 intersects Method Testing*

##### Test Case ID: TC\_RNG\_025

**Test Objective:** Equivalence Class Testing \- Validate intersection scenarios.

**Test Input:**

* Range(5,10), checking intersection with Range(7,12).

* Range(5,10), checking intersection with Range(10,15).

* Range(5,10), checking intersection with Range(1,4).

**Expected Output:**

* The method returns true for overlapping ranges and false for non-overlapping ranges.

**Test Steps:**

1. Create a Range(5,10).

2. Check intersection with Range(7,12).

3. Check intersection with Range(10,15).

4. Check intersection with Range(1,4).

5. Verify returned results.

**Actual Result (upon execution):**

* Test Failure: testIntersects\_WithOverlappingRange

* Test Failure: testIntersects\_WithNonOverlappingRange

* Test Failure: testIntersects\_WithTouchingRange

**Pass/Fail Criteria:**

* The test passes if the method correctly determines intersection scenarios.

##### Test Case ID: TC\_RNG\_026

**Test Objective:** Boundary Value Analysis \- Check for exact and near-boundary intersections.

**Test Input:**

* Range(5,10), checking intersection with Range(10,15).

* Range(5,10), checking intersection with Range(4.9999,5).

**Expected Output:**

* The method correctly determines intersection at exact boundary values.

**Test Steps:**

1. Create a Range(5,10).

2. Check intersection with Range(10,15).

3. Check intersection with Range(4.9999,5).

4. Verify returned results.

**Actual Result (upon execution):**

* Test Pass: testIntersects\_AtExactLowerBoundary

* Test Failure: testIntersects\_AtExactUpperBoundary

**Pass/Fail Criteria:**

* The test passes if the method correctly handles near-boundary cases.

##### Test Case ID: TC\_RNG\_027

**Test Objective:** Robustness Testing \- Handle invalid values and overlapping cases.

**Test Input:**

* null range checking intersection with Range(5,10).

* Range(5,10), checking intersection with Range(Double.MIN\_VALUE, Double.MAX\_VALUE).

**Expected Output:**

* The method handles invalid inputs gracefully and determines intersection correctly.

**Test Steps:**

1. Attempt to check intersection of a null range.

2. Check intersection of Range(5,10) with an extremely large range.

3. Verify returned results and exception handling.

**Actual Result (upon execution):**

* Test Pass: testIntersects\_WithNullRange

* Test Pass: testIntersects\_WithExtremeRange

**Pass/Fail Criteria:**

* The test passes if the method handles invalid inputs correctly.

##### Test Case ID: TC\_RNG\_028

**Test Objective:** Worst-Case Testing \- Check intersection calculations with large range sets.

**Test Input:**

* Range(-1e9,1e9), checking intersection with Range(0,1e9+1).

**Expected Output:**

* The method correctly determines intersection without performance degradation.

**Test Steps:**

1. Create a Range(-1e9,1e9).

2. Check intersection with Range(0,1e9+1).

3. Verify execution efficiency and correctness.

**Actual Result (upon execution):**

* Test Failure: testIntersects\_WithLargeRangeSet

**Pass/Fail Criteria:**

* The test passes if the method correctly handles large range sets while maintaining performance.

#### *3.1.4.8 shift Method Testing*

##### Test Case ID: TC\_RNG\_029

**Test Objective:** Equivalence Class Testing \- Verify correct shifting behavior.

**Test Input:**

* Range(5,10), shifting by 2, allowZeroCrossing=true.

* Range(5,10), shifting by \-2, allowZeroCrossing=true.

* Range(5,10), shifting by 2, allowZeroCrossing=false.

**Expected Output:**

* The method correctly shifts the range based on input parameters.

**Test Steps:**

1. Create a Range(5,10).

2. Shift it by 2 and \-2 with allowZeroCrossing=true.

3. Shift it by 2 with allowZeroCrossing=false.

4. Verify the expected shifted range.

**Actual Result (upon execution):**

* Test Failure: testShift\_PositiveShift\_AllowZeroCrossing

* Test Failure: testShift\_NegativeShift\_AllowZeroCrossing

* Test Failure: testShift\_PositiveShift\_NoZeroCrossing

**Pass/Fail Criteria:**

* The test passes if the method correctly shifts the range.

##### Test Case ID: TC\_RNG\_030

**Test Objective:** Boundary Value Analysis \- Test shift by zero and extreme values.

**Test Input:**

* Range(5,10), shifting by 0\.

* Range(5,10), shifting by Double.MAX\_VALUE.

* Range(5,10), shifting by \-Double.MAX\_VALUE.

**Expected Output:**

* The method correctly handles shift by zero and extreme values.

**Test Steps:**

1. Create a Range(5,10).

2. Shift it by 0, Double.MAX\_VALUE, and \-Double.MAX\_VALUE.

3. Verify the returned results.

**Actual Result (upon execution):**

* Test Failure: testShift\_ByZero

* Test Pass: testShift\_ByNegativeMaxValue

* Test Pass: testShift\_ByMaxValue

**Pass/Fail Criteria:**

* The test passes if the method correctly handles boundary values.

##### Test Case ID: TC\_RNG\_031

**Test Objective:** Robustness Testing \- Handle null and negative ranges.

**Test Input:**

* null range shifting by 5\.

* Range(-10,-1), shifting by 3\.

**Expected Output:**

* The method throws an appropriate exception for null inputs and handles negative ranges properly.

**Test Steps:**

1. Attempt to shift a null range by 5\.

2. Create a Range(-10,-1), shift it by 3\.

3. Verify that the method correctly handles invalid cases.

**Actual Result (upon execution):**

* Test Failure: testShift\_WithNegativeRange

* Test Pass: testShift\_WithNullRange

**Pass/Fail Criteria:**

* The test passes if exceptions are properly handled or negative range shifts work correctly.

##### Test Case ID: TC\_RNG\_032

**Test Objective:** Worst-Case Testing \- Shift range to an extreme position.

**Test Input:**

* Range(-1e9,1e9), shifting by 1e12, allowZeroCrossing=true.

**Expected Output:**

* The method correctly shifts the range without performance degradation.

**Test Steps:**

1. Create a Range(-1e9,1e9).

2. Shift it by 1e12.

3. Verify execution efficiency and correctness.

**Actual Result (upon execution):**

* Test Failure: testShift\_WithExtremePositiveShift

**Pass/Fail Criteria:**

* The test passes if the method correctly shifts the range while maintaining performance.

## 3.2 Abubakar Khalid Test Cases Developed

### 3.2.1 Test Strategy {#3.2.1-test-strategy}

The testing approach follows black-box testing techniques to ensure the correctness of the `createNumberArray()` method. The primary testing strategies include:

* Equivalence Class Testing: Ensures that valid, invalid, and boundary cases are properly handled.  
* Boundary Value Analysis: Tests cases with the smallest and largest possible values.  
* Robustness Testing: Ensures the method correctly processes special values such as `Double.MIN_VALUE`, `Double.MAX_VALUE`, and `NaN`.  
* Error Handling: Ensures that invalid inputs like `null` trigger the expected exceptions.

All test cases are executed using JUnit, and assertions verify the correctness of the output.

#### *Test Types* {#test-types}

The following testing techniques were used:

* Equivalence Class Testing: Ensuring valid and invalid values are handled correctly.  
* Boundary Value Analysis: Testing lower and upper limits of input values.  
* Robustness Testing: Checking behavior with extreme values (e.g., `Double.MAX_VALUE`, `Double.MIN_VALUE`).  
* Error Handling: Ensuring null values throw exceptions as expected.

---

### 3.2.2 Test Case Documentation for `createNumberArray()` {#3.2.2-test-case-documentation-for-createnumberarray()}

Test Case 1 \- Convert a valid array of doubles into a `Number[]` array

* Test Input: `{1.5, 2.5, 3.5}`  
* Expected Output: `{1.5, 2.5, 3.5}`  
* Actual Output: `{1.5, 2.5, null}`  
* Result:  Failed (The last element returned `null` instead of `3.5`)  
* Notes: This indicates a potential issue with how `createNumberArray()` converts `double[]` values into `Number[]`.

Test Case 2 \- Convert an empty array

* Test Input: `{}`  
* Expected Output: `{}` (Empty `Number[]`)  
* Actual Output: `{}`  
* Result: Passed

Test Case 3 \- Convert an array with a single element

* Test Input: `{4.2}`  
* Expected Output: `{4.2}`  
* Actual Output: `{4.2}`  
* Result: Passed

Test Case 4 \- Convert an array with negative values

* Test Input: `{-1.0, -2.5, -3.3}`  
* Expected Output: `{-1.0, -2.5, -3.3}`  
* Actual Output: `{-1.0, -2.5, -3.3}`  
* Result: Passed

Test Case 5 \- Convert an array with zero values

* Test Input: `{0.0, 0.0, 0.0}`  
* Expected Output: `{0.0, 0.0, 0.0}`  
* Actual Output: `{0.0, 0.0, 0.0}`  
* Result: Passed

Test Case 6 \- Convert an array with `Double.MAX_VALUE`

* Test Input: `{Double.MAX_VALUE, 1.0}`  
* Expected Output: `{Double.MAX_VALUE, 1.0}`  
* Actual Output: `{Double.MAX_VALUE, 1.0}`  
* Result: Passed

Test Case 7 \- Convert an array with `Double.MIN_VALUE`

* Test Input: `{Double.MIN_VALUE, 2.0}`  
* Expected Output: `{Double.MIN_VALUE, 2.0}`  
* Actual Output: `{Double.MIN_VALUE, 2.0}`  
* Result:  Passed

Test Case 8 \- Convert an array containing `NaN` values

* Test Input: `{1.0, Double.NaN, 3.0}`  
* Expected Output: `{1.0, NaN, 3.0}`  
* Actual Output: `{1.0, NaN, 3.0}`  
* Result: Passed

Test Case 9 \- Convert an array with an extremely large number of elements (Stress Test)

* Test Input: `{1.0, 2.0, ..., 1_000_000.0}`  
* Expected Output: `{1.0, 2.0, ..., 1_000_000.0}`  
* Actual Output: `{1.0, 2.0, ..., 1_000_000.0}`  
* Result: Passed

Test Case 10 \- Handle a `null` input

* Test Input: `null`  
* Expected Output: Throws `InvalidParameterException`  
* Actual Output: Throws `InvalidParameterException`  
* Result: Passed

### 3.2.3 Notes on Results {#3.2.3-notes-on-results}

Bug Found:

* The first test case failed (`TCA-01`).  
* The last element of the returned array was `null` instead of `3.5`.  
* This suggests a bug in `createNumberArray()` that prevents the last element from being converted properly.

Severity:

* Medium – The function does not completely convert all elements correctly but does not cause a crash.

### 3.2.4 Test Case Documentation for createNumberArray2D() {#3.2.4-test-case-documentation-for-createnumberarray2d()}

Test Case 1 \- Convert a valid 2D array of doubles into a Number\[\]\[\] array  
Test Input:  
{  
    {1.1, 2.2, 3.3},  
    {4.4, 5.5, 6.6}  
}  
Expected Output:  
{  
    {1.1, 2.2, 3.3},  
    {4.4, 5.5, 6.6}  
}  
Actual Output:  
{  
    {1.1, 2.2, null},  
    {4.4, 5.5, 6.6}  
}  
Result: Failed (The last element in the first row was null instead of 3.3)  
Notes: This indicates a potential issue with how createNumberArray2D() converts double\[\]\[\] values into Number\[\]\[\].

Test Case 2 \- Convert an empty 2D array  
Test Input: {}  
Expected Output: {} (Empty Number\[\]\[\])  
Actual Output: {}  
Result: Passed

Test Case 3 \- Convert a 2D array with a single row  
Test Input:  
{  
    {7.7, 8.8, 9.9}  
}  
Expected Output:  
{  
    {7.7, 8.8, 9.9}  
}  
Actual Output:  
{  
    {7.7, 8.8, 9.9}  
}  
Result: Passed

Test Case 4 \- Convert a 2D array with negative values  
Test Input:  
{  
    {-1.1, \-2.2, \-3.3},  
    {-4.4, \-5.5, \-6.6}  
}  
Expected Output:  
{  
    {-1.1, \-2.2, \-3.3},  
    {-4.4, \-5.5, \-6.6}  
}  
Actual Output:  
{  
    {-1.1, \-2.2, \-3.3},  
    {-4.4, \-5.5, \-6.6}  
}  
Result: Passed

Test Case 5 \- Convert a 2D array with zero values  
Test Input:  
{  
    {0.0, 0.0, 0.0},  
    {0.0, 0.0, 0.0}  
}  
Expected Output:  
{  
    {0.0, 0.0, 0.0},  
    {0.0, 0.0, 0.0}  
}  
Actual Output:  
{  
    {0.0, 0.0, 0.0},  
    {0.0, 0.0, 0.0}  
}  
Result: Passed

Test Case 6 \- Convert a 2D array with Double.MAX\_VALUE  
Test Input:  
{  
    {Double.MAX\_VALUE, 1.0},  
    {2.0, 3.0}  
}  
Expected Output:  
{  
    {Double.MAX\_VALUE, 1.0},  
    {2.0, 3.0}  
}  
Actual Output:  
{  
    {Double.MAX\_VALUE, 1.0},  
    {2.0, 3.0}  
}  
Result: Passed

Test Case 7 \- Convert a 2D array with Double.MIN\_VALUE  
Test Input:  
{  
    {Double.MIN\_VALUE, 2.0},  
    {3.0, 4.0}  
}  
Expected Output:  
{  
    {Double.MIN\_VALUE, 2.0},  
    {3.0, 4.0}  
}  
Actual Output:  
{  
    {Double.MIN\_VALUE, 2.0},  
    {3.0, 4.0}  
}  
Result: Passed

Test Case 8 \- Convert a 2D array containing NaN values  
Test Input:  
{  
    {1.0, Double.NaN, 3.0},  
    {4.0, 5.0, 6.0}  
}  
Expected Output:  
{  
    {1.0, NaN, 3.0},  
    {4.0, 5.0, 6.0}  
}  
Actual Output:  
{  
    {1.0, NaN, 3.0},  
    {4.0, 5.0, 6.0}  
}  
Result: Passed

Test Case 9 \- Convert an extremely large 2D array (Stress Test)  
Test Input: 1000x1000 matrix of increasing values  
Expected Output: 1000x1000 matrix of increasing values  
Actual Output: 1000x1000 matrix of increasing values  
Result: Passed

Test Case 10 \- Handle a null input  
Test Input: null  
Expected Output: Throws InvalidParameterException  
Actual Output: Throws InvalidParameterException  
Result: Passed

### 3.2.5 Notes on Results {#3.2.5-notes-on-results}

Bug Found:  
The first test case failed (TCA-01).  
The last element in the first row was null instead of 3.3.  
This suggests a bug in createNumberArray2D() that prevents the last value in a row from being converted correctly.

Severity:  
Medium – The function does not correctly handle all elements in a 2D array but does not cause a crash.

## 3.3 Ahmed Shehata Test Cases Developed

### 3.3.1 Test Strategy {#3.3.1-test-strategy}

The testing approach follows black-box testing and systematic test design techniques, ensuring:

* Equivalence Class Testing: Ensures values inside, outside, and at boundaries are tested.  
* Boundary Value Analysis: Tests values at lower and upper limits.  
* Robustness Testing: Ensures extreme values are handled correctly.  
* Worst-Case Testing: Evaluates performance under high computational load.

All test cases are executed using JUnit, and assertions ensure the correctness of expected outputs.

### 3.3.2 Test Case Documentation for Each Method {#3.3.2-test-case-documentation-for-each-method}

#### *3.3.2.1 Method: contains(double value)* {#3.3.2.1-method:-contains(double-value)}

Test Strategy:

* Ensure that values within, outside, and at the boundaries are correctly handled.  
* Validate negative ranges.  
* Ensure that extreme values, such as Double.MIN\_VALUE, Double.MAX\_VALUE, and NaN, do not cause errors.

Test Case Design:

| Test Case ID | Test Objective | Test Input | Expected Output |
| :---- | :---- | :---- | :---- |
| TC\_RNG\_033 | Value at the lower bound | Range(5,10).contains(5) | true |
| TC\_RNG\_034 | Value at the upper bound | Range(5,10).contains(5) | true |
| TC\_RNG\_035 | Value inside the range | Range(5,10).contains(7.5) | true |
| TC\_RNG\_036 | Value below the range | Range(5,10).contains(3) | false |
| TC\_RNG\_037 | Value above the range | Range(5,10).contains(12) | false |
| TC\_RNG\_038 | Value inside a negative range | Range(-10,-5).contains(-7) | true |
| TC\_RNG\_039 | Value outside a negative range | Range(-10,-5).contains(-11) | false |
| TC\_RNG\_040 | Value at zero (inside a range including zero) | Range(-5,5).contains(0) | true |
| TC\_RNG\_041 | Value inside a very large range | Range(-1e9,1e9).contains(0) | true |
| TC\_RNG\_042 | Value outside a very large range | Range(-1e9,1e9).contains(1e12) | false |
| TC\_RNG\_043 | Single-point range contains its own value | Range(3,3).contains(3) | true |
| TC\_RNG\_044 | Single-point range should not contain other values | Range(3,3).contains(4) | false |
| TC\_RNG\_045 | Handling Double.MIN\_VALUE | Range(Double.MIN\_VALUE, 10).contains(Double.MIN\_VALUE) | true |
| TC\_RNG\_046 | Handling Double.MAX\_VALUE | Range(-10, Double.MAX\_VALUE).contains(Double.MAX\_VALUE) | true |
| TC\_RNG\_047 | Handling NaN values | Range(5,10).contains(Double.NaN) | false |

#### *3.3.2.2 Method: `getCentralValue()`* {#3.3.2.2-method:-getcentralvalue()}

Test Strategy:

* Verify that the method correctly calculates the central (median) value of a range.  
* Handle negative ranges and zero-based ranges.  
* Test behavior for very large ranges and single-point ranges.

Test Case Design:

| Test Case ID | Test Objective | Test Input | Expected Output |
| :---- | :---- | :---- | :---- |
| TC\_RNG\_048 | Central value of a positive range | Range(5,10).getCentralValue() | 7.5 |
| TC\_RNG\_049 | Central value of a negative range | Range(-10,-5).getCentralValue() | \-7.5 |
| TC\_RNG\_050 | Central value when range includes zero | Range(-5,5).getCentralValue() | 0.0 |
| TC\_RNG\_051 | Central value when lower bound is zero | Range(0,10).getCentralValue() | 5.0 |
| TC\_RNG\_052 | Central value of a single-point range | Range(3,3).getCentralValue() | 3.0 |
| TC\_RNG\_053 | Central value of a large range | Range(-1e9,1e9).getCentralValue() | 0.0 |
| TC\_RNG\_054 | Central value of extreme range near Double.MIN\_VALUE | Range(Double.MIN\_VALUE,10).getCentralValue() | (Double.MIN\_VALUE \+ 10\) / 2 |
| TC\_RNG\_055 | Central value of extreme range near Double.MAX\_VALUE | Range(-10,Double.MAX\_VALUE).getCentralValue() | (-10 \+ Double.MAX\_VALUE) / 2 |
| TC\_RNG\_056 | Central value of a large negative range | Range(-1e12,-1e6).getCentralValue() | (-1e12 \+ \-1e6) / 2 |
| TC\_RNG\_057 | Central value of a small decimal range | Range(0.0001,0.0005).getCentralValue() | 0.0003 |

#### *3.3.2.3 Method: `getLength()`* {#3.3.2.3-method:-getlength()}

Test Strategy:

* Verify correct length computation for different types of ranges.  
* Handle zero-width ranges.  
* Ensure large and extreme ranges do not cause errors.

Test Case Design:

| Test Case ID | Test Objective | Test Input | Expected Output |
| :---- | :---- | :---- | :---- |
| TC\_RNG\_058 | Length of a positive range | Range(5,10).getLength() | 5.0 |
| TC\_RNG\_059 | Length of a negative range | Range(-10,-5).getLength() | 5.0 |
| TC\_RNG\_060 | Length of a range including zero | Range(-5,5).getLength() | 10.0 |
| TC\_RNG\_061 | Length of a zero-width range | Range(3,3).getLength() | 0.0 |
| TC\_RNG\_062 | Length of a large range | Range(-1e9,1e9).getLength() | 2e9 |
| TC\_RNG\_063 | Length of an extreme range near Double.MIN\_VALUE | Range(Double.MIN\_VALUE,10).getLength() | 10 \- Double.MIN\_VALUE |
| TC\_RNG\_064 | Length of an extreme range near Double.MAX\_VALUE | Range(-10, Double.MAX\_VALUE).getLength() | Double.MAX\_VALUE \+ 10 |
| TC\_RNG\_065 | Length of a large negative range | Range(-1e12,-1e6).getLength() | (-1e6 \+ 1e12) |
| TC\_RNG\_066 | Length of a small decimal range | Range(0.0001,0.0005).getLength() | 0.0004 |

## 3.4 Jinyu Wang Test Cases Developed

### 3.4.1 Test Ranger.combine() {#3.4.1-test-ranger.combine()}

#### *3.4.1.1 Test strategies* {#3.4.1.1-test-strategies}

##### 1\. Equivalence Class Partitioning (ECP) {#1.-equivalence-class-partitioning-(ecp)}

This strategy **divides input values into distinct classes** such that testing one value from each class is enough to represent all cases within that class. The equivalence classes considered:

* **Null Cases**:  
  * Both `range1` and `range2` are `null`.  
  * One of `range1` or `range2` is `null`.  
* **Overlapping vs. Non-Overlapping Ranges**:  
  * `range1` and `range2` are **completely separate** (e.g., `(1,5)` and `(10,15)`).  
  * `range1` and `range2` are **touching** at a boundary (e.g., `(1,5)` and `(5,10)`).  
  * `range1` and `range2` **partially overlap** (e.g., `(1,6)` and `(4,10)`).  
  * `range1` is **fully contained** within `range2` (or vice versa).  
* **Identical Ranges**:  
  * `range1` and `range2` are the **same** (e.g., `(1,5)` and `(1,5)`).  
* **Single-Point Ranges**:  
  * Both ranges represent the **same single point** (e.g., `(3,3)` and `(3,3)`).  
  * Two **adjacent single-point ranges** (e.g., `(3,3)` and `(4,4)`).  
* **Boundary Cases**:  
  * **Lower boundary:** `Integer.MIN_VALUE`  
  * **Upper boundary:** `Integer.MAX_VALUE`  
  * **Zero boundary:** Cases involving zero.

---

##### 2\. Boundary Value Analysis (BVA) {#2.-boundary-value-analysis-(bva)}

BVA is used to test **extreme values and edges** of the input domain. This ensures the function behaves correctly at **critical limits**.

* **Lower Boundaries:**  
  * Smallest possible integer (`Integer.MIN_VALUE`).  
  * A negative range that transitions to a positive (`-5, 0` and `0, 5`).  
* **Upper Boundaries:**  
  * Largest possible integer (`Integer.MAX_VALUE`).  
  * A range that extends up to **Integer.MAX\_VALUE** (e.g., `(10, Integer.MAX_VALUE)`).  
* **Transition Points:**  
  * **Touching ranges** (`(1,5)` and `(5,10)`) to ensure **merging happens correctly**.  
  * **Overlapping ranges** (`(1,6)` and `(4,10)`) to verify **expansion is correct**.  
  * **Zero crossing** (`(-5,0)` and `(0,5)`) to check behavior at zero boundary.

#### *3.4.1.2 Test cases design* {#3.4.1.2-test-cases-design}

##### A. Handling Null Inputs {#a.-handling-null-inputs}

These tests verify how the method handles `null` values.

* **Test Case 1: Both Ranges Are Null**  
  * **Description**: If both input ranges are `null`, the method should return `null`.  
  * **Expected Output**: `null`.  
* **Test Case 2: First Range Is Null**  
  * **Description**: If `range1` is `null`, the method should return `range2`.  
  * **Expected Output**: `range2`.  
* **Test Case 3: Second Range Is Null**  
  * **Description**: If `range2` is `null`, the method should return `range1`.  
  * **Expected Output**: `range1`.

---

##### B. Merging Different Range Scenarios {#b.-merging-different-range-scenarios}

These tests cover different relationships between `range1` and `range2`.

* **Test Case 4: Non-Overlapping Ranges**  
  * **Description**: Two ranges that do not overlap should be merged into a new range covering both.  
  * **Input**: `(1,5)` and `(10,15)`  
  * **Expected Output**: `(1,15)`  
* **Test Case 5: Touching Ranges**  
  * **Description**: Two ranges that touch at the boundary should be merged into a continuous range.  
  * **Input**: `(1,5)` and `(5,10)`  
  * **Expected Output**: `(1,10)`  
* **Test Case 6: Overlapping Ranges**  
  * **Description**: Two overlapping ranges should be merged into a single range spanning both.  
  * **Input**: `(1,6)` and `(4,10)`  
  * **Expected Output**: `(1,10)`  
* **Test Case 7: Identical Ranges**  
  * **Description**: If both ranges are identical, the method should return the same range.  
  * **Input**: `(1,5)` and `(1,5)`  
  * **Expected Output**: `(1,5)`  
* **Test Case 8: One Range Inside Another**  
  * **Description**: If one range is fully contained inside another, the method should return the larger range.  
  * **Input**: `(1,10)` and `(3,7)`  
  * **Expected Output**: `(1,10)`

---

##### C. Boundary Conditions {#c.-boundary-conditions}

These tests evaluate special boundary cases, including `Integer.MIN_VALUE` and `Integer.MAX_VALUE`.

* **Test Case 9: Lower Boundary (Integer.MIN\_VALUE)**  
  * **Description**: Merging a range with `Integer.MIN_VALUE` should still work correctly.  
  * **Input**: `(Integer.MIN_VALUE, -1)` and `(0,5)`  
  * **Expected Output**: `(Integer.MIN_VALUE,5)`  
* **Test Case 10: Upper Boundary (Integer.MAX\_VALUE)**  
  * **Description**: Merging a range with `Integer.MAX_VALUE` should still work correctly.  
  * **Input**: `(10, Integer.MAX_VALUE)` and `(5,9)`  
  * **Expected Output**: `(5, Integer.MAX_VALUE)`  
* **Test Case 11: Zero Boundary**  
  * **Description**: Merging two ranges where one boundary is `0` should work correctly.  
  * **Input**: `(-5,0)` and `(0,5)`  
  * **Expected Output**: `(-5,5)`

---

##### D. Handling Single-Point Ranges {#d.-handling-single-point-ranges}

These tests check how the method handles ranges where the lower and upper bounds are the same.

* **Test Case 12: Identical Single-Point Ranges**  
  * **Description**: If both ranges are the same single-point range, return it as is.  
  * **Input**: `(3,3)` and `(3,3)`  
  * **Expected Output**: `(3,3)`  
* **Test Case 13: Adjacent Single-Point Ranges**  
  * **Description**: If two single-point ranges are adjacent, they should be merged into a larger range.  
  * **Input**: `(3,3)` and `(4,4)`  
  * **Expected Output**: `(3,4)`

### 3.4.2 Test Range.constrain() {#3.4.2-test-range.constrain()}

#### *3.4.2.1 Test strategy* {#3.4.2.1-test-strategy}

##### Equivalence Class Partitioning (ECP) {#equivalence-class-partitioning-(ecp)}

The input space is divided into four major equivalence classes:

1. **Inside the range:** Values within the specified range `(lower ≤ value ≤ upper)`.  
2. **Below the range:** Values **less than** the lower boundary `(value < lower)`.  
3. **Above the range:** Values **greater than** the upper boundary `(value > upper)`.  
4. **At boundaries:** Values exactly at the **lower** or **upper** boundary `(value == lower or value == upper)`.

##### Boundary Value Analysis (BVA) {#boundary-value-analysis-(bva)}

To test edge behavior, the following cases are considered:

* **Lower Boundary:** `value == lower`  
* **Upper Boundary:** `value == upper`  
* **Just Below Lower Boundary:** `value < lower` but very close to it  
* **Just Above Upper Boundary:** `value > upper` but very close to it  
* **Far Below the Range:** `value << lower`  
* **Far Above the Range:** `value >> upper`

#### *3.4.2.2 Test case design* {#3.4.2.2-test-case-design}

##### A. Inside the Range {#a.-inside-the-range}

* **Test Case 1: Value within the range**  
  * **Test Strategy**: Inside the range (ECP)  
  * **Input**: `value = 5`, `range = (2,8)`  
  * **Expected Output**: `5` (unchanged)

##### B. Boundary Cases {#b.-boundary-cases}

* **Test Case 2: Lower boundary value**  
  * **Test Strategy**: Lower boundary inside the range (BVA)  
  * **Input**: `value = 2`, `range = (2,8)`  
  * **Expected Output**: `2`  
* **Test Case 3: Upper boundary value**  
  * **Test Strategy**: Upper boundary inside the range (BVA)  
  * **Input**: `value = 8`, `range = (2,8)`  
  * **Expected Output**: `8`

##### C. Below the Range {#c.-below-the-range}

* **Test Case 4: Value below the lower boundary**  
  * **Test Strategy**: Below the range (ECP)  
  * **Input**: `value = 0`, `range = (2,8)`  
  * **Expected Output**: `2` (lower bound)  
* **Test Case 5: Far below the lower boundary**  
  * **Test Strategy**: Far below the range (BVA)  
  * **Input**: `value = -5`, `range = (2,8)`  
  * **Expected Output**: `2` (lower bound)  
* **Test Case 6: Just below the lower boundary**  
  * **Test Strategy**: Just below the lower boundary (BVA)  
  * **Input**: `value = 1.9999`, `range = (2,8)`  
  * **Expected Output**: `2` (lower bound)  
* **Test Case 7: Slightly lower than the range**  
  * **Test Strategy**: Lower boundary outside the range (BVA)  
  * **Input**: `value = 1`, `range = (2,8)`  
  * **Expected Output**: `2` (lower bound)

##### D. Above the Range {#d.-above-the-range}

* **Test Case 8: Value above the upper boundary**  
  * **Test Strategy**: Above the range (ECP)  
  * **Input**: `value = 10`, `range = (2,8)`  
  * **Expected Output**: `8` (upper bound)  
* **Test Case 9: Far above the upper boundary**  
  * **Test Strategy**: Far above the range (BVA)  
  * **Input**: `value = 100`, `range = (2,8)`  
  * **Expected Output**: `8` (upper bound)  
* **Test Case 10: Just above the upper boundary**  
  * **Test Strategy**: Just above the upper boundary (BVA)  
  * **Input**: `value = 8.0001`, `range = (2,8)`  
  * **Expected Output**: `8` (upper bound)  
* **Test Case 11: Slightly higher than the range**  
  * **Test Strategy**: Upper boundary outside the range (BVA)  
  * **Input**: `value = 9`, `range = (2,8)`  
  * **Expected Output**: `8` (upper bound)

### 3.4.3 Test DataUtilities.getCumulativePercentages() {#3.4.3-test-datautilities.getcumulativepercentages()}

#### *3.4.3.1 Test strategy* {#3.4.3.1-test-strategy}

##### Equivalence Class Partitioning (ECP) {#equivalence-class-partitioning-(ecp)-1}

* **Valid normal cases** include datasets with multiple positive values.  
* **Edge cases** include a dataset with only one value.  
* **Zero-inclusive datasets** check whether zero affects calculations.  
* **Negative value datasets** ensure the function processes negative numbers correctly.  
* **Invalid input cases** test null input.  
* **Empty datasets** verify that the function correctly returns an empty result.

##### Boundary Value Analysis (BVA) {#boundary-value-analysis-(bva)-1}

* The function is tested with the **minimum dataset size** (a single value).  
* Datasets that **contain zero** ensure correct computation.  
* **Negative values** test whether the function handles them properly.  
* A **null dataset** should trigger an exception.  
* An **empty dataset** should return an empty result.

#### *3.4.3.2 Test case design* {#3.4.3.2-test-case-design}

##### A. Valid Cases {#a.-valid-cases}

* **Test Case 1: Standard Dataset with Positive Values**  
  * **Test Strategy:** Normal case (ECP)  
  * **Description:** Computes cumulative percentages correctly for a dataset with positive values.  
  * **Input:**  
    * Keyed values: `{ (0, 5), (1, 9), (2, 2) }`  
  * **Expected Output:**  
    * `{ (0, 0.3125), (1, 0.875), (2, 1.0) }`  
* **Test Case 2: Single-Value Dataset**  
  * **Test Strategy:** Minimum input size (BVA)  
  * **Description:** A dataset with only one value should return 1.0.  
  * **Input:**  
    * Keyed values: `{ (0, 10) }`  
  * **Expected Output:**  
    * `{ (0, 1.0) }`

---

##### B. Edge Cases {#b.-edge-cases}

* **Test Case 3: Dataset Including Zero Values**  
  * **Test Strategy:** Handling zero values (ECP)  
  * **Description:** Ensures zero does not affect cumulative percentage calculations.  
  * **Input:**  
    * Keyed values: `{ (0, 5), (1, 0), (2, 5) }`  
  * **Expected Output:**  
    * `{ (0, 0.5), (1, 0.5), (2, 1.0) }`  
* **Test Case 4: Dataset with Negative Values**  
  * **Test Strategy:** Handling negative numbers (ECP)  
  * **Description:** Ensures that negative values are handled correctly.  
  * **Input:**  
    * Keyed values: `{ (0, -3), (1, 5), (2, 4) }`  
  * **Expected Output:**  
    * `{ (0, -0.3), (1, 0.2), (2, 1.0) }`

---

##### C. Invalid Cases {#c.-invalid-cases}

* **Test Case 5: Null Input**  
  * **Test Strategy:** Invalid input (ECP)  
  * **Description:** The method should throw an `InvalidParameterException` when the dataset is null.  
  * **Input:**  
    * `null`  
  * **Expected Output:**  
    * Throws `InvalidParameterException`  
* **Test Case 6: Empty Dataset**  
  * **Test Strategy:** Edge case (ECP)  
  * **Description:** The method should return an empty dataset.  
  * **Input:**  
    * Keyed values: `{ }`  
  * **Expected Output:**  
    * `{ }`

# 4 How the Team Work/Effort was Divided and Managed

The team worked collaboratively to complete the assignment by dividing tasks based on individual expertise and interest. The methods to be tested were assigned as follows:

## 4.1 Responsibilities:

Members methods testing selection is as provided below:

| Assigned to: | Class DataUtilities Method Summary |  |
| :---- | :---- | :---- |
| Mohammad | static double | **calculateColumnTotal(Values2D data, int column) Returns the sum of the values in one column of the supplied data table.** |
| Mohammad | static double | **calculateRowTotal(Values2D data, int row) Returns the sum of the values in one row of the supplied data table.** |
| Abu Baker | static java.lang.Number\[\] | **createNumberArray(double\[\] data) Constructs an array of Number objects from an array of double primitives.** |
| Abu Baker | static java.lang.Number\[\]\[\] | **createNumberArray2D(double\[\]\[\] data) Constructs an array of arrays of Number objects from a corresponding structure containing double primitives.** |
| Jinyu | static KeyedValues | **getCumulativePercentages(KeyedValues data) Returns a KeyedValues instance that contains the cumulative percentage values for the data in another KeyedValues instance.** |
|  | **Class Range Method Summary** |  |
| Jinyu | static Range | **combine(Range range1, Range range2) Creates a new range by combining two existing ranges.** |
| Jinyu | double | **constrain(double value) Returns the value within the range that is closest to the specified value.** |
| Ahmed | boolean | **contains(double value) Returns true if the specified value is within the range and false otherwise.** |
| Mohammad | boolean | **equals(java.lang.Object obj) Tests this object for equality with an arbitrary object.** |
| Mohammad | static Range | **expand(Range range, double lowerMargin, double upperMargin) Creates a new range by adding margins to an existing range.** |
| Mohammad | static Range | **expandToInclude(Range range, double value) Returns a range that includes all the values in the specified range AND contains the specified value.** |
| Ahmed | double | **getCentralValue() Returns the central (or median) value for the range.** |
| Ahmed | double | **getLength() Returns the length of the range.** |
| Mohammad | double | **getLowerBound() Returns the lower bound for the range.** |
| Mohammad | double | **getUpperBound() Returns the upper bound for the range.** |
| Mohammad | int | **hashCode() Returns a hash code.** |
| Mohammad | boolean | **intersects(double lower, double upper) Returns true if the range intersects (overlaps) with the specified range, and false otherwise.** |
| Mohammad | static Range | **shift(Range base, double delta) Returns a range the size of the input range, which has been moved positively (to the right) by the delta value.** |

## 4.2 Collaboration and Coordination:

The team used an iterative approach to ensure quality and accuracy in testing. We followed these steps:

1. **Initial Research and Setup:** The team ensured that all members were familiar with JUnit testing, JMock, and the structure of the JFreeChart framework.

2. **Test Design and Documentation:** Each member documented their test case designs before implementing the tests to ensure proper coverage.

3. **Implementation:** Each member wrote and executed JUnit test cases for their assigned methods.

4. **Code Review and Refinements:** The team conducted peer reviews to ensure test quality and completeness.

5. **Final Integration and Report Compilation:** The test cases were compiled into a single test suite, and the final report was assembled collaboratively.

By following this structured approach, the team was able to efficiently distribute work, minimize redundant efforts, and ensure high-quality testing across all assigned methods.

# 5 Difficulties Encountered, Challenges Overcome, and Lessons Learned

Throughout this assignment, we encountered several challenges that required problem-solving, technical understanding, and effective teamwork. One of the main difficulties was understanding the intricacies of requirement-based testing using JUnit and mock objects. Initially, integrating JMock with JUnit proved to be challenging, as some team members were unfamiliar with mocking frameworks. Through collaboration, studying documentation, and troubleshooting errors, we successfully implemented mock objects to test methods requiring interface dependencies.

Another challenge we faced was ensuring consistency in test case design. Since multiple team members were working on different methods, it was crucial to maintain a uniform test structure. At first, we noticed discrepancies in the level of detail, naming conventions, and assertions used in our test cases. To overcome this, we established a standardized test format, ensuring that all test cases followed the same structure with well-defined input partitions, expected outputs, and assertion methods. This standardization improved readability and maintainability of our test suite.

Handling boundary value analysis and robustness testing also posed difficulties. Some edge cases, such as extreme values or unexpected inputs, led to unexpected failures or unclear results. By reviewing the JFreeChart documentation and conducting exploratory testing, we were able to refine our test cases and better understand the expected behavior of the methods under test. This process reinforced the importance of thorough requirement analysis before designing test cases.

A significant technical challenge was debugging failed test cases. Some failures were due to incorrect assumptions about method behavior, while others stemmed from minor errors such as floating-point precision mismatches. To address this, we conducted group debugging sessions, reviewed method specifications in the JFreeChart Javadoc, and utilized debugging tools in Eclipse. These efforts helped us resolve ambiguities and improve our test assertions.

Time management was another obstacle. Balancing this assignment with other coursework required effective scheduling and task distribution. By dividing responsibilities early and setting internal deadlines, we ensured steady progress. Regular team meetings helped us track progress, discuss roadblocks, and provide assistance when needed.

One of the most valuable lessons we learned was the importance of clear documentation and collaboration. Standardizing our test case format, maintaining organized reports, and conducting peer reviews significantly improved the quality of our work. Additionally, this assignment reinforced our understanding of requirement-based testing, mocking frameworks, and best practices in unit testing.

Overall, this assignment provided valuable hands-on experience in structured testing methodologies, debugging techniques, and team collaboration. The challenges we faced ultimately strengthened our problem-solving skills and understanding of software testing principles, better preparing us for real-world testing scenarios.

# 6 Comments/Feedback on the Lab Itself

Overall, this lab provided a valuable and practical learning experience in software testing. The structured approach to requirement-based testing helped us develop a deeper understanding of test case design, mocking frameworks, and JUnit testing methodologies. The hands-on implementation reinforced theoretical concepts and highlighted the importance of thorough test planning.

One of the strengths of this lab was its focus on real-world testing scenarios. Working with JFreeChart, an actual open-source framework, provided a realistic environment that simulated industry-level software testing challenges. The requirement to use Javadoc documentation as a reference for test design was particularly useful, as it emphasized the role of software documentation in quality assurance.

However, there were some aspects of the lab that could be improved. The initial setup process was somewhat challenging due to version compatibility issues with JMock and JUnit. More detailed setup instructions, including troubleshooting steps, would have been beneficial in reducing the initial learning curve. Additionally, clearer guidelines on expected test coverage and the level of detail required in test cases would help ensure consistency among different teams.

Another suggestion for improvement would be the inclusion of automated tools for test case execution and coverage analysis. While JUnit provides a solid foundation for unit testing, integrating additional tools such as JaCoCo for code coverage reporting could enhance the learning experience and provide deeper insights into test effectiveness.

Despite these minor challenges, the lab was well-structured and effectively reinforced key testing principles. It encouraged teamwork, problem-solving, and critical thinking, all of which are essential skills for software testing professionals. The challenges we faced during this assignment ultimately strengthened our understanding of the software testing process, preparing us for future industry applications.

